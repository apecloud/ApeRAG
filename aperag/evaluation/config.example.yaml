api:
  base_url: "http://localhost:8000/api/v1"
  api_token: "${APERAG_API_KEY}"

# LLM Configuration for Ragas evaluation
llm_for_eval:
  # These can be overridden by environment variables
  api_base: "https://openrouter.ai/api/v1"
  api_key: "${OPENROUTER_API_KEY}"
  model: "openai/gpt-4o-mini"
  temperature: 0

# Embedding Configuration for Ragas evaluation (optional)
embeddings_for_eval:
  # If not provided, will try to use the same as llm_for_eval
  # You can also use local models or set to null to skip embedding-based metrics
  api_base: "https://api.siliconflow.cn/v1"
  api_key: "{SILICONFLOW_API_KEY}"
  model: "BAAI/bge-m3"
  # Set to null to disable embedding-based metrics
  # api_base: null

# Evaluation Tasks
evaluations:
  - task_name: "Demo Evaluation - Three Kingdoms Q&A (All Metrics)"
    # Replace with your bot ID
    bot_id: "bot61b56647225effd1"
    dataset_path: "./evaluation/threekingdoms/datasets/qa.csv"
    # Optional: limit the number of samples (useful for testing)
    max_samples: 3
    # Output directory for reports
    report_dir: "./evaluation/threekingdoms/report"
    # Metrics to evaluate - all supported Ragas metrics
    metrics:
      - faithfulness          # 忠实性评估 (仅需LLM)
      - answer_relevancy      # 答案相关性评估 (需要embedding)
      - context_precision     # 上下文精确性评估 (需要LLM和ground truth)
      - context_recall        # 上下文召回率评估 (需要LLM和ground truth)
      - answer_correctness    # 答案正确性评估 (需要LLM和ground truth)

# Advanced settings
advanced:
  request_timeout: 30  # API request timeout in seconds
  request_delay: 3     # Delay between requests in seconds to avoid rate limits
  # Batch size for processing (to avoid overwhelming the API)
  batch_size: 3
  # Whether to save intermediate results
  save_intermediate: true 