/* tslint:disable */
/* eslint-disable */
/**
 * ApeRAG API
 * ApeRAG API Documentation
 *
 * The version of the OpenAPI document: 1.0.0
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


import type { Configuration } from '../configuration';
import type { AxiosPromise, AxiosInstance, RawAxiosRequestConfig } from 'axios';
import globalAxios from 'axios';
// Some imports not used depending on template conditions
// @ts-ignore
import { DUMMY_BASE_URL, assertParamExists, setApiKeyToObject, setBasicAuthToObject, setBearerAuthToObject, setOAuthToObject, setSearchParams, serializeDataIfNeeded, toPathString, createRequestFunction } from '../common';
// @ts-ignore
import { BASE_PATH, COLLECTION_FORMATS, type RequestArgs, BaseAPI, RequiredError, operationServerMap } from '../base';
// @ts-ignore
import type { EmbeddingRequest } from '../models';
// @ts-ignore
import type { EmbeddingResponse } from '../models';
// @ts-ignore
import type { FailResponse } from '../models';
/**
 * EmbeddingApi - axios parameter creator
 * @export
 */
export const EmbeddingApiAxiosParamCreator = function (configuration?: Configuration) {
    return {
        /**
         * Generate embeddings for the given input text(s) using the specified provider and model. This endpoint is compatible with OpenAI\'s embeddings API format, but includes an additional \'provider\' parameter to specify which LLM provider to use.  The endpoint supports both single text inputs and batch processing of multiple texts. It requires the provider to be configured in the user\'s Model Service Provider (MSP) settings with a valid API key. 
         * @summary Create embeddings
         * @param {EmbeddingRequest} embeddingRequest 
         * @param {*} [options] Override http request option.
         * @throws {RequiredError}
         */
        embeddingsPost: async (embeddingRequest: EmbeddingRequest, options: RawAxiosRequestConfig = {}): Promise<RequestArgs> => {
            // verify required parameter 'embeddingRequest' is not null or undefined
            assertParamExists('embeddingsPost', 'embeddingRequest', embeddingRequest)
            const localVarPath = `/embeddings`;
            // use dummy base URL string because the URL constructor only accepts absolute URLs.
            const localVarUrlObj = new URL(localVarPath, DUMMY_BASE_URL);
            let baseOptions;
            if (configuration) {
                baseOptions = configuration.baseOptions;
            }

            const localVarRequestOptions = { method: 'POST', ...baseOptions, ...options};
            const localVarHeaderParameter = {} as any;
            const localVarQueryParameter = {} as any;

            // authentication CookieAuth required

            // authentication BearerAuth required
            // http bearer authentication required
            await setBearerAuthToObject(localVarHeaderParameter, configuration)


    
            localVarHeaderParameter['Content-Type'] = 'application/json';

            setSearchParams(localVarUrlObj, localVarQueryParameter);
            let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
            localVarRequestOptions.headers = {...localVarHeaderParameter, ...headersFromBaseOptions, ...options.headers};
            localVarRequestOptions.data = serializeDataIfNeeded(embeddingRequest, localVarRequestOptions, configuration)

            return {
                url: toPathString(localVarUrlObj),
                options: localVarRequestOptions,
            };
        },
    }
};

/**
 * EmbeddingApi - functional programming interface
 * @export
 */
export const EmbeddingApiFp = function(configuration?: Configuration) {
    const localVarAxiosParamCreator = EmbeddingApiAxiosParamCreator(configuration)
    return {
        /**
         * Generate embeddings for the given input text(s) using the specified provider and model. This endpoint is compatible with OpenAI\'s embeddings API format, but includes an additional \'provider\' parameter to specify which LLM provider to use.  The endpoint supports both single text inputs and batch processing of multiple texts. It requires the provider to be configured in the user\'s Model Service Provider (MSP) settings with a valid API key. 
         * @summary Create embeddings
         * @param {EmbeddingRequest} embeddingRequest 
         * @param {*} [options] Override http request option.
         * @throws {RequiredError}
         */
        async embeddingsPost(embeddingRequest: EmbeddingRequest, options?: RawAxiosRequestConfig): Promise<(axios?: AxiosInstance, basePath?: string) => AxiosPromise<EmbeddingResponse>> {
            const localVarAxiosArgs = await localVarAxiosParamCreator.embeddingsPost(embeddingRequest, options);
            const localVarOperationServerIndex = configuration?.serverIndex ?? 0;
            const localVarOperationServerBasePath = operationServerMap['EmbeddingApi.embeddingsPost']?.[localVarOperationServerIndex]?.url;
            return (axios, basePath) => createRequestFunction(localVarAxiosArgs, globalAxios, BASE_PATH, configuration)(axios, localVarOperationServerBasePath || basePath);
        },
    }
};

/**
 * EmbeddingApi - factory interface
 * @export
 */
export const EmbeddingApiFactory = function (configuration?: Configuration, basePath?: string, axios?: AxiosInstance) {
    const localVarFp = EmbeddingApiFp(configuration)
    return {
        /**
         * Generate embeddings for the given input text(s) using the specified provider and model. This endpoint is compatible with OpenAI\'s embeddings API format, but includes an additional \'provider\' parameter to specify which LLM provider to use.  The endpoint supports both single text inputs and batch processing of multiple texts. It requires the provider to be configured in the user\'s Model Service Provider (MSP) settings with a valid API key. 
         * @summary Create embeddings
         * @param {EmbeddingApiEmbeddingsPostRequest} requestParameters Request parameters.
         * @param {*} [options] Override http request option.
         * @throws {RequiredError}
         */
        embeddingsPost(requestParameters: EmbeddingApiEmbeddingsPostRequest, options?: RawAxiosRequestConfig): AxiosPromise<EmbeddingResponse> {
            return localVarFp.embeddingsPost(requestParameters.embeddingRequest, options).then((request) => request(axios, basePath));
        },
    };
};

/**
 * EmbeddingApi - interface
 * @export
 * @interface EmbeddingApi
 */
export interface EmbeddingApiInterface {
    /**
     * Generate embeddings for the given input text(s) using the specified provider and model. This endpoint is compatible with OpenAI\'s embeddings API format, but includes an additional \'provider\' parameter to specify which LLM provider to use.  The endpoint supports both single text inputs and batch processing of multiple texts. It requires the provider to be configured in the user\'s Model Service Provider (MSP) settings with a valid API key. 
     * @summary Create embeddings
     * @param {EmbeddingApiEmbeddingsPostRequest} requestParameters Request parameters.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof EmbeddingApiInterface
     */
    embeddingsPost(requestParameters: EmbeddingApiEmbeddingsPostRequest, options?: RawAxiosRequestConfig): AxiosPromise<EmbeddingResponse>;

}

/**
 * Request parameters for embeddingsPost operation in EmbeddingApi.
 * @export
 * @interface EmbeddingApiEmbeddingsPostRequest
 */
export interface EmbeddingApiEmbeddingsPostRequest {
    /**
     * 
     * @type {EmbeddingRequest}
     * @memberof EmbeddingApiEmbeddingsPost
     */
    readonly embeddingRequest: EmbeddingRequest
}

/**
 * EmbeddingApi - object-oriented interface
 * @export
 * @class EmbeddingApi
 * @extends {BaseAPI}
 */
export class EmbeddingApi extends BaseAPI implements EmbeddingApiInterface {
    /**
     * Generate embeddings for the given input text(s) using the specified provider and model. This endpoint is compatible with OpenAI\'s embeddings API format, but includes an additional \'provider\' parameter to specify which LLM provider to use.  The endpoint supports both single text inputs and batch processing of multiple texts. It requires the provider to be configured in the user\'s Model Service Provider (MSP) settings with a valid API key. 
     * @summary Create embeddings
     * @param {EmbeddingApiEmbeddingsPostRequest} requestParameters Request parameters.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof EmbeddingApi
     */
    public embeddingsPost(requestParameters: EmbeddingApiEmbeddingsPostRequest, options?: RawAxiosRequestConfig) {
        return EmbeddingApiFp(this.configuration).embeddingsPost(requestParameters.embeddingRequest, options).then((request) => request(this.axios, this.basePath));
    }
}

