name: basic_flow
title: "Basic Flow"
description: "A basic flow"
version: "1.0.0"
# Execution configuration
execution:
  timeout: 300 # Overall timeout (seconds)
  retry:
    max_attempts: 3
    delay: 5
  error_handling:
    strategy: "stop_on_error" # or "continue_on_error"
    notification:
      email: ["admin@example.com"]

schema:
  document_with_score:
    type: object
    properties:
      doc_id:
        type: string
      text:
        type: string
      score:
        type: number
      metadata:
        type: object


# Node definitions
nodes:
  # Start node
  - id: start
    type: start
    title: Start
    data:
      input:
        schema:
          type: object
          properties:
            query:
              type: string
              description: User's question or query
          required: [query]
        values:
          query: "hello"
      output:
        schema:
          type: object
          properties:
            query:
              type: string
              description: User's question or query
          required: [query]

  # LLM generation node
  - id: llm_8e4f2a7b
    type: llm
    title: LLM Generation
    data:
      input:
        schema:
          type: object
          properties:
            model_service_provider:
              type: string
              default: openrouter
              description: model service provider
            model_name:
              type: string
              default: deepseek/deepseek-v3-base:free
              description: model name
            custom_llm_provider:
              type: string
              default: openrouter
              description: custom llm provider
            prompt_template:
              type: string
              default: "{query}"
              description: Prompt template
            temperature:
              type: number
              default: 0.7
              minimum: 0
              maximum: 1
              description: Sampling temperature
            query:
              type: string
              description: User's question or query
          required: [model_service_provider, model_name, custom_llm_provider, prompt_template, temperature, query]
        values:
          model_service_provider: openrouter
          model_name: deepseek/deepseek-v3-base:free
          custom_llm_provider: openrouter
          prompt_template: "{query}"
          temperature: 0.7
          query: "{{ nodes.start.output.query }}"
      output:
        schema:
          type: object
          properties:
            text:
              type: string
              description: text generated by LLM

# Edge definitions (connections between nodes)
edges:
  # Start to LLM
  - source: start
    target: llm_8e4f2a7b 